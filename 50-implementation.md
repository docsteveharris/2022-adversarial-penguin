# Implementation science

Unlike medications, algorithms can only impact health by influencing the behaviour of clinicians and patients. This corresponds to the second (T2) arm of translational medicine: implementation science.[@woolf2008b] A well designed, safe, and responsible AI algorithm may still be ineffective if it does not reach a modifiable target on the clinical pathway.[@the2021] Implementation requires a multi-disciplinary approach including human-computer interaction, behavioural science, and qualitative analysis.[@sendak2020] 

We strongly argue that this task will be more difficult if done offline and in isolation. Pillar 1 crucially permits not just tuning of the technical performance of the algorithm but rapid build-test-learn cycles that directly involve the target user and the clinical pathway in question. This approach will reduce costs and improve impact, sometimes leading to trade-offs which might appear surprising to those developing away from the bedside.[@shah2019; @morse2020a] This efficiency will again depend on the problem space: where the algorithmic target depends on information arising from the EHR rather than an isolated device or image, and where the pathway involves multiple end-users, then successful implementation will be near impossible if done sequentially (development then deployment) rather than iteratively.[@sendak2020; @connell2019] Academic health science centres must become design 'laboratories' where rapid prototyping (build-test-learn) at the bedside crafts the deployment pathway for effectiveness rather than just efficacy.    

Investigations to define how then system can influence behaviour will need specialist support and tooling. This might require tools embedded within the user interface to evaluate and monitor user interaction, and capture user feedback[@yusop2017], or directed implementation studies.[@sutton2020]

Despite the oft cited risks of alert fatigue with Clinical Decision Support Systems (CDSS)[@phansalkar2013], there is good evidence that well designed alerts can be impactful.[@park2022; @sayres2019; @main2010] Overt behavioural modifications will need a mechanism to explain their recommendation (as per XAI) or generate trust (see Pillar 5).[@mccoy2022] Trust will possibly be more important where behaviour modification is indirect through non-interruptive techniques (e.g. re-ordering preference lists or otherwise adapting the user interface to make the recommended choice more accessible).
